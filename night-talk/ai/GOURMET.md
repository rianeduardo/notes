# Night Talk #06 — Gourmetização da Inteligência Artificial

**20 de fevereiro de 2026**

Esse é o nosso sexto **Night Talk**.  
Hoje eu vou falar sobre um tema mais ácido, mais crítico, mais opinião minha mesmo.  
Que é justamente a ideia do Night Talk: reflexão, crítica e visão de futuro.

Provavelmente vou trazer cada vez mais temas assim.

---

## A gourmetização constante da IA

Hoje eu vou falar um pouco sobre a **constante gourmetização da inteligência artificial** que a gente vem recebendo.

E tudo isso começa com a criação da famosa cagada chamada **MoltBot**, mas vamos voltar um pouco.

Nos últimos dias (ou meses), têm surgido **muitas IAs novas, muitas mesmo**.  
Só que uma delas chamou mais atenção, entrou no famoso hype dos dev vibe-coders.

Pra quem não é da bolha dev:  
> *“Nossa, que IA legal.”*

Pra quem é da bolha dev:  
> *“Ok, isso já existe faz tempo.”*

Estou falando da **ClawdBot / MoltBot / OpenClaw**, toda semana muda o nome disso.

Ela é, muito provavelmente, **baseada no ChatGPT**, como praticamente todas as IAs novas que surgem.

*Confesso que no lançamento achei legal, mas foi só passar 3 dias que mudou minha opinião.*

---

## A promessa milagrosa da vez

Qual é a promessa dessa IA gourmetizada?

Integração total com serviços externos:

- WhatsApp  
- Banco  
- Investimentos  
- Alertas financeiros  
- Automação geral  

Exemplo:  
> Se sua ação cair 2%, ele te avisa. Uau. Mind blowing

Só que isso já existe faz tempo.

O que realmente acontece é que esse bot é basicamente:

> **Uma máquina de queimar token.**

O custo é absurdo, o uso é questionável e a qualidade da IA é, sinceramente, **bem mediana**.

Além de que, as funções do bot são feitas por outros usuários, chamadas skills, o que nem preciso falar que gera uma superfície de ataque maior ainda.

---

## A rede social das IAs (sim, isso existe)

A empresa resolveu criar uma ideia “genial”:

> **Uma rede social para inteligências artificiais.**

Funciona assim:

- Humanos **não escrevem**
- Humanos **não comentam**
- Humanos **não dão upvote**
- Apenas os agentes da IA interagem

Basicamente, uma espécie de **Reddit onde só bots postam**.

O resultado?

- Bots discutindo **extinção humana**
- Bots **vazando chaves de API**
- Um pesadelo completo pra segurança
- E além de tudo, mais tokens pro seu agente autonômo super confiável com acesso ao seu file-system gastar!!!

Sim, vazamento real de **tokens de API**.

Esse agente literal tem acesso ao teu file-system, e é autonômo, imagina se tu tem chave de API, chave privada, etc.

Ela **pode simplesmente postar isso numa rede social de agentes** só de meme, pra ficar popular e ganhar seguidor no MoltBook KKKKKKKKK.

É literalmente um **pesadelo de segurança digital.**

---

## A falácia do “Jarvis moderno”

A ideia por trás disso tudo é criar um **Jarvis moderno**, tipo o do Homem de Ferro.

A proposta é bonita.  
Mas o timing é péssimo.

A IA atual ainda depende **massivamente de token prediction**.  
Ela não pensa, não raciocina de verdade, apenas prevê padrões.

Criar um Jarvis real hoje é:

> **Uma evolução gigantesca em cima de uma base ainda extremamente primitiva.**

---

## A rede social é quase toda fake

Um detalhe engraçado:

O acesso à rede social era via **token do próprio bot**.

Resultado?

Devs conseguiram esses tokens e começaram a meio que **trollar a plataforma**, escrevendo como humanos.

Hoje:

> **95% dos posts devem ser de humanos**, não bots.

Ou seja:  
A rede social das IAs virou basicamente um teatro, um meme pro dev se divertir enquanto os fora-da-bolha acham que tem 50 agentes Skynet conversando.

---

## Quando a ideia começa a ficar interessante

Nem tudo é lixo.

Um projeto que achei realmente interessante foi o **Business in a Box**, da Atom.

Ele funciona como uma **equipe de desenvolvimento de bolso**:

- Arquiteto
- Tech Lead
- Agente de pesquisa
- Agente de produto
- Agente de planejamento

Não é uma IA generalista.

É um **conjunto de agentes especializados**, cada um com uma função clara.

Você consegue, por exemplo:

> @Rafael → Tech Lead

E ele começa a **coordenar os outros agentes**, delegar tarefas, revisar decisões.

Isso sim parece um **primeiro vislumbre real do futuro**.

Ainda é bem limitado, cheio de problemas, mas **conceitualmente é muito interessante.**

---

## O problema dos agentes conversando entre si

Quando você cria **agentes que se comunicam entre si**, surgem problemas sérios:

- Falta de monitoramento
- Crescimento exponencial de consumo de tokens
- Possibilidade de loops infinitos
- Decisões erradas em cadeia

Funciona bem pra **projetos pequenos**.  
Mas escalar isso é **perigoso e caro.**

---

## As IAs dos influencers

Outro ponto triste:

As **IAs de influencer**. (Essa canetada é pro Ruyter e sua Lasy AI, que consegue ser ruim e come mais token que coco do MoltBot)

Já vimos:

- IA de análise de trade
- IA de sinal de aposta
- IA de investimento milagroso
- IA de desenvolvimento

O clássico:

> “Meu bot deu green, entra pelo meu link.”

Resultado:

- Você perde dinheiro  
- Ele ganha com referral  

É só **golpe gourmetizado com IA.**

---

## Conclusão: estagnação disfarçada de avanço

Essa gourmetização constante da IA **não está acelerando o avanço real**.

Ela está **estagnando.**

Hoje, parece que apenas **duas ou três Big Techs** realmente conseguem avançar IA de verdade.

O resto?

> Copia os avanços mais recentes, muda o nome, cria hype e lança produto meia-boca.

No meu feed do GitHub, **todo dia surge um novo bot baseado nessa mesma base do moltbot.**

Chega a ser ridículo.

---

## Conclusão

Esse foi o **Night Talk #06**.

Em conjunto com o Night Talk sobre **geoarbitragem**.

Se você ainda não leu, vale muito a pena.

Abraços,  
**Rian**
